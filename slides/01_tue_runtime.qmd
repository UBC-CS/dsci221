---
title: "Counting Steps"
subtitle: "Week 1, Tuesday"
date: 2026-01-06
---

# From Monday

## Algorithm Analysis

1. **Correctness** â€” Does it work?
2. **Efficiency** â€” How long? How much memory?

:::{.notes}
"This week: efficiency. Next week: proving correctness."
:::

## The Shazam Lesson

Naive search: "Linear" â€” too slow

Hash lookup: "Constant" â€” instant

:::{.notes}
"Today: How do we figure out which is which?"
:::


## Linear Search

``` {pyodide}
def find_song_naive(sample, database):
    for song in database:
        if matches(sample, song):
            return song
    return None
```

| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | ... | 99,999,999 |
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
| ðŸŽµ | ðŸŽµ | ðŸŽµ | ðŸŽµ | ðŸŽµ | ðŸŽµ | ðŸŽµ | ðŸŽµ | ... | ðŸŽµ |

- What does this do?

- How many [lines of code]{.red} are executed?

:::{.notes}

we'll be more precise now -- give a mathematical function.
:::

## Aside for Cases


``` {pyodide}
def find_song_naive(sample, database):
    for song in database:
        if matches(sample, song):
            return song
    return None
```

| `sample` is at position... | time |
|---------------------|-------------|
| 0 | instant |
| 5 | longer|
| 15 | longer |
| not in array | longest |


- **Best case**: minimum over all inputs
- **Worst case**: maximum over all inputs
- **Average case**: expected (needs probability)


:::{.notes}
"The answer depends on the input!"

Best case: 1
Worst case: n
Average case: (1+2+...+n)/n = (n+1)/2 â‰ˆ n/2

"Which should we report?"

we will do worst case, almost always.
:::

## Counting Everything

``` {pyodide}
def \_\_\_\_\_\_\_\_(arr):
    temp = arr[0]      
    for x in arr:          
        if x > temp:   
            temp = x    
    return temp        
```

- What's a good name? 

- What's a good expression for running time? $T(n) = $

:::{.notes}
"Does the 2 matter?"

At n = 1,000,000: 2n â‰ˆ n. Constants are noise.

The SHAPE matters: linear.
:::

# Discovering Patterns

## Single Loop

```{python}
#| eval: false
for i in range(n):
    do_something()
```

| n | operations |
|---|------------|
| 10 | 10 |
| 100 | 100 |
| 1000 | 1000 |

:::{.notes}
"What's the pattern?"

Double n â†’ double the work. LINEAR.
:::

## Nested Loops

```{python}
#| eval: false
count = 0
for i in range(n):
    for j in range(n):
        count += 1
```

Trace for n = 4. How many increments?

:::{.notes}
Let them trace: 16

"Predict for n = 8?" (64)

Double n â†’ QUADRUPLE the work. QUADRATIC.
:::

## Nested Loops (variant)

```{python}
#| eval: false
count = 0
for i in range(n):
    for j in range(i):
        count += 1
```

Trace for n = 5.

:::{.notes}
i=0: 0. i=1: 1. i=2: 2. i=3: 3. i=4: 4. Total: 10.

0 + 1 + 2 + ... + (n-1) = n(n-1)/2

Still quadratic!
:::

## The Triangle Sum

$$1 + 2 + 3 + \ldots + n = \frac{n(n+1)}{2}$$

:::{.notes}
"This is O(nÂ²), not O(n)."

Whenever you see "all pairs" â€” expect quadratic.
:::

## The Halving Pattern

```{python}
#| eval: false
count = 0
i = n
while i > 1:
    count += 1
    i = i // 2
```

Trace for n = 1000.

:::{.notes}
1000 â†’ 500 â†’ 250 â†’ 125 â†’ 62 â†’ 31 â†’ 15 â†’ 7 â†’ 3 â†’ 1

About 10 iterations. logâ‚‚(1000) â‰ˆ 10.

"What if n = 1,000,000?" (â‰ˆ20)

Double n â†’ ONE more step. LOGARITHMIC.
:::

## Let's verify

```{pyodide}
import math

n = 1000
i = n
count = 0
while i > 1:
    print(f"i = {i}")
    i = i // 2
    count += 1

print(f"\nIterations: {count}")
print(f"logâ‚‚({n}) = {math.log2(n):.1f}")
```

## Pattern Summary

| Pattern | What happens when n doubles? | Name |
|---------|------------------------------|------|
| Single loop | Work doubles | O(n) |
| Nested loops | Work quadruples | O(nÂ²) |
| Halving | One more step | O(log n) |

:::{.notes}
"These are the building blocks."
:::

## Big-O Notation {.smaller}

::: {.columns}
::: {.column width="55%"}

| Notation | Name |
|----------|------|
| O(1) | Constant |
| O(log n) | Logarithmic |
| O(n) | Linear |
| O(n log n) | Linearithmic |
| O(nÂ²) | Quadratic |
| O(2â¿) | Exponential |

:::

::: {.column width="45%"}
```{python}
#| echo: false
import matplotlib.pyplot as plt
import numpy as np

n = np.linspace(1, 15, 100)
const = np.ones_like(n)
log_n = np.log2(n) * 2
linear = n * 1.5
n_log_n = n * np.log2(n) * 0.8
quadratic = n ** 2 / 4
exponential = 2 ** (n / 2.5)

plt.figure(figsize=(5, 4))
plt.plot(n, const, '-', linewidth=2.5, label='O(1)')
plt.plot(n, log_n, '-', linewidth=2.5, label='O(log n)')
plt.plot(n, linear, '-', linewidth=2.5, label='O(n)')
plt.plot(n, n_log_n, '-', linewidth=2.5, label='O(n log n)')
plt.plot(n, quadratic, '-', linewidth=2.5, label='O(nÂ²)')
plt.plot(n, exponential, '-', linewidth=2.5, label='O(2â¿)')
plt.xlabel('n')
plt.ylabel('Time')
plt.ylim(0, 70)
plt.xlim(1, 15)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```
:::
:::

:::{.notes}
"We'll formalize this Wednesday."
:::

# DataFrame Operations

## Which pattern?

```{python}
#| eval: false
df['col'].sum()
df[df['col'] > 5]
df.loc[12345]
df.merge(other_df)
```

:::{.notes}
Let them reason:

- sum: touch every value â†’ O(n)
- filter: check every row â†’ O(n)
- loc: direct access â†’ O(1)
- merge: ???

"Is merge O(nÂ²)? It compares rows..."
:::

## The Merge Mystery

`df.merge()` uses hashing internally.

O(n), not O(nÂ²).

:::{.notes}
"We'll learn how in Week 5."
:::

## Galactic Pizza

```{pyodide}
#| echo: false
import pandas as pd
import numpy as np
import time

n = 500_000
np.random.seed(42)

df = pd.DataFrame({
    'delivery_time': np.random.exponential(scale=30, size=n),
    'planet': np.random.choice(['Earth', 'Mars', 'Europa', 'Titan'], n),
})

print(f"Rows: {len(df):,}")
print(df.head(8))
```

## Two ways to compute the mean

```{pyodide}
def iter_mean(df, col):
    total = 0
    for idx, row in df.iterrows():
        total += row[col]
    return total / len(df)

start = time.time()
avg1 = iter_mean(df, 'delivery_time')
t1 = time.time() - start

start = time.time()
avg2 = df['delivery_time'].mean()
t2 = time.time() - start

print(f"Loop:       {t1:.3f} sec")
print(f"Vectorized: {t2:.5f} sec")
print(f"Speedup:    {t1/t2:,.0f}x")
```

:::{.notes}
"Both are O(n). Why the difference?"
:::

## Same Big-O, Different Speed

Both touch every row: O(n)

But:

- **Vectorized**: tiny constants (compiled C)
- **Python loop**: large constants (interpreter overhead)

:::{.notes}
"Big-O tells you SCALING, not SPEED."
:::

# Summary

## What we learned

1. Trace code to count operations
2. Cases: best, worst, average
3. Patterns: linear, quadratic, logarithmic
4. Big-O describes the shape

## Wednesday

The full hierarchy. Racing algorithms. Feeling the difference.

:::{.notes}
"And we'll finally see how Shazam's O(1) lookup works."
:::


<!-- from Monday: 


## Constants Don't Matter

T(n) = 2n + 1?

:::{.notes}
"Does the 2 matter? Does the +1 matter?"

At n = 100,000,000, the constants are noise.

What matters is the SHAPE: linear growth.

"We write this as O(n)."
:::

## Growth Rates {.smaller}

::: {.columns}
::: {.column width="45%"}
**Algorithm A**

| n | time |
|---|------|
| 10 | 1 sec |
| 50 | 5 sec |
| 100 | 10 sec |

**Algorithm B**

| n | time |
|---|------|
| 10 | 1 sec |
| 50 | 25 sec |
| 100 | 100 sec |
:::

::: {.column width="55%"}
```{python}
#| echo: false
import matplotlib.pyplot as plt
import numpy as np

n = np.linspace(1, 100, 100)
algo_a = n * 0.1
algo_b = (n ** 2) * 0.01

plt.figure(figsize=(5, 4))
plt.plot(n, algo_a, 'b-', linewidth=2, label='Algorithm A')
plt.plot(n, algo_b, 'r-', linewidth=2, label='Algorithm B')
plt.xlabel('Input size (n)')
plt.ylabel('Time (seconds)')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```
:::
:::

:::{.notes}
"What's the pattern for A? For B?"

A: linear (time âˆ n)
B: quadratic (time âˆ nÂ²)
:::

## What about pandas?

You'll work with DataFrames that have **millions of rows**.

Some operations are fast. Others are slow.

:::{.notes}
"Why?"

- `df['col'].sum()` â€” must touch every value
- `df.loc[12345]` â€” goes directly to one row
- `df.iterrows()` â€” visits every row, with Python overhead

"We'll learn to predict which is which."
:::

# Back to Shazam


--> 